{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_prepared.json\") as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing.json\") as f:\n",
    "    testData = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = dict()\n",
    "\n",
    "for sentence in data:\n",
    "    for word in sentence[\"text\"]:\n",
    "        if word not in word_index:\n",
    "            word_index[word] = 1\n",
    "        else:\n",
    "            word_index[word]+= 1\n",
    "            \n",
    "sortedDictionary = sorted(word_index.items(), key=operator.itemgetter(1),reverse=True)    \n",
    "\n",
    "wordMatrix = np.zeros(shape=(len(data), 7000)) \n",
    "\n",
    "vocabulary = dict()\n",
    "for i in range(7000):\n",
    "    vocabulary[sortedDictionary[i][0]] = i\n",
    "\n",
    "row = 0\n",
    "\n",
    "for sentence in data:\n",
    "    for word in sentence[\"text\"]:\n",
    "        if word in vocabulary:\n",
    "            wordMatrix[row, vocabulary[word]]+=1\n",
    "    row+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = list()\n",
    "sentiment = 0\n",
    "\n",
    "for i in range(len(wordMatrix)):\n",
    "    if data[i][\"manual_sentiment\"] == \"positive\":\n",
    "        sentiment = 1\n",
    "    elif data[i][\"manual_sentiment\"] == \"neutral\":\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        sentiment = -1\n",
    "    wordVectors.append((wordMatrix[i],sentiment))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('BagWords.pkl', 'wb') as f:\n",
    "    pickle.dump(wordVectors,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word2Vec vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "sentiment = []\n",
    "neutral = 0\n",
    "positive = 0\n",
    "for item in data:\n",
    "    if item[\"manual_sentiment\"] == \"neutral\" and neutral < 30000:\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(0)\n",
    "        neutral+=1\n",
    "    elif item[\"manual_sentiment\"] == \"positive\" and positive < 25000:\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(1)\n",
    "        positive+=1\n",
    "    elif item[\"manual_sentiment\"] == \"negative\":\n",
    "        text.append(item[\"text\"])\n",
    "        sentiment.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 120\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(text,workers=num_workers, size=num_features,\\\n",
    "                          min_count = min_word_count,window=context, sample=downsampling)\n",
    "model.init_sims(replace = True)\n",
    "model_name = \"word2vec\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words,model,num_features):\n",
    "    featureVec = np.zeros((num_features,), dtype='float32')\n",
    "    n = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n+=1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,n)\n",
    "    return featureVec\n",
    "\n",
    "def getAverageVec(posts, model,num_features):\n",
    "    cnt = 0\n",
    "    reviewFeatureVecs = np.zeros((len(posts), num_features), dtype='float32')\n",
    "    \n",
    "    for sentence in posts:\n",
    "        reviewFeatureVecs[cnt] = makeFeatureVec(sentence,model,num_features)\n",
    "        cnt+=1\n",
    "    return reviewFeatureVecs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danit/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "DataVecs = getAverageVec(text,model,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(DataVecs).any()\n",
    "np.count_nonzero(np.isnan(DataVecs))\n",
    "DataVecs = np.nan_to_num(DataVecs)\n",
    "np.isnan(DataVecs).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"text.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DataVecs,f)\n",
    "    \n",
    "with open(\"sentiment.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sentiment,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.34336267e-04,   1.33666266e-02,   1.04589080e-02,\n",
       "         2.11514346e-02,   2.51224004e-02,  -2.01841034e-02,\n",
       "         1.48397684e-02,  -1.06298262e-02,   1.10759595e-02,\n",
       "         1.57386921e-02,   9.19556245e-03,   1.40464082e-02,\n",
       "         5.60426340e-03,   1.60362758e-02,   1.33384243e-02,\n",
       "        -8.08512967e-04,  -5.03373472e-03,   1.22603471e-03,\n",
       "         6.05679210e-03,  -3.51574528e-03,  -3.25760469e-02,\n",
       "         4.43344153e-02,   2.04750933e-02,  -2.62582605e-03,\n",
       "        -1.47328863e-03,  -4.02599180e-05,   1.03632752e-02,\n",
       "        -1.95809081e-03,   7.53942586e-04,   1.10852607e-02,\n",
       "        -1.68742966e-02,  -4.42791777e-03,   3.64656821e-02,\n",
       "        -2.04444062e-02,  -1.35190170e-02,   2.40673907e-02,\n",
       "         1.21841412e-02,  -9.18254536e-03,  -2.42143292e-02,\n",
       "        -5.45758009e-03,  -3.45048420e-02,  -1.62998196e-02,\n",
       "        -1.19103435e-02,  -1.64612511e-03,  -1.71572808e-02,\n",
       "        -2.95967311e-02,   1.03858467e-02,   8.99517071e-03,\n",
       "         5.06902812e-03,  -1.32448999e-02,  -3.47230467e-04,\n",
       "         1.47190848e-02,   9.34525859e-03,  -1.67417023e-02,\n",
       "         3.50311538e-03,   1.45561900e-02,  -1.37987714e-02,\n",
       "        -6.26459997e-03,  -1.81103498e-02,   2.02670712e-02,\n",
       "        -5.09974407e-03,  -1.54419765e-02,   3.72719020e-02,\n",
       "        -4.22873236e-02,   8.57500266e-03,  -1.08091868e-02,\n",
       "        -4.69788648e-02,  -6.88683148e-03,  -2.23913211e-02,\n",
       "        -2.89829187e-02,  -2.66236980e-02,  -1.03960251e-02,\n",
       "        -6.64367527e-03,  -1.24531649e-02,  -3.02326772e-03,\n",
       "         2.42361743e-02,  -1.79454293e-02,   2.75744833e-02,\n",
       "         1.28804306e-02,   5.02073811e-03,  -3.23040150e-02,\n",
       "        -9.41354781e-03,   7.18605053e-03,   1.36204064e-04,\n",
       "         2.06173267e-02,  -1.45859886e-02,  -5.03038801e-03,\n",
       "        -1.14658126e-03,   2.99647264e-02,  -2.84955259e-02,\n",
       "         1.94506720e-02,  -1.30522978e-02,   8.62071384e-03,\n",
       "         2.41384725e-03,  -2.92700995e-02,   1.11056697e-02,\n",
       "         2.06157174e-02,   1.29000647e-02,   5.57796971e-04,\n",
       "        -3.39061283e-02,  -2.28578271e-03,  -3.65239289e-03,\n",
       "        -2.04660334e-02,  -9.17767547e-03,   1.70391649e-02,\n",
       "        -1.74846128e-02,  -2.01337039e-02,  -1.69231482e-02,\n",
       "         2.57534394e-03,   2.55428031e-02,   1.92344319e-02,\n",
       "         5.92936715e-03,   5.41545730e-03,  -2.96212360e-03,\n",
       "         2.33827834e-03,   9.29960422e-03,   1.29276756e-02,\n",
       "        -1.26365339e-02,  -3.93149406e-02,  -1.26566635e-02], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
